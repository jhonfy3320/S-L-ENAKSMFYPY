{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La validación cruzada de K-Folds (K-Folds Cross Validation) es una técnica que se utiliza para evaluar el rendimiento de un modelo de manera más robusta que simplemente dividir los datos en conjuntos de entrenamiento y prueba. En lugar de realizar una sola división de los datos, K-Folds divide los datos en K particiones o \"pliegues\" (folds) y entrena y prueba el modelo K veces, utilizando un fold diferente como conjunto de prueba en cada iteración. Luego, se promedian las métricas de rendimiento de todas las iteraciones para obtener una estimación más precisa del rendimiento del modelo.\n",
    "\n",
    "### Aquí hay un ejemplo de cómo implementar K-Folds Cross Validation en scikit-learn utilizando el conjunto de datos felicidad.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cuadrado Medio Promedio (K-Folds): 1.2827998073351925\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = pd.read_csv('/home/jhonfypy/CursoML_Scikit_learni_jf/felicidad.csv')\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = data.drop(columns=['score'])\n",
    "y = data['score']\n",
    "\n",
    "# Definir las características categóricas (en este caso, la columna 'country')\n",
    "categorical_features = ['country']\n",
    "\n",
    "# Crear un transformador one-hot para las características categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar los transformadores para todas las características\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Crear un modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Crear un pipeline que incluye el preprocesamiento y el modelo\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "\n",
    "# Definir el número de particiones (folds)\n",
    "num_folds = 5\n",
    "\n",
    "# Crear un objeto KFold para dividir los datos\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializar una lista para almacenar los resultados de cada fold\n",
    "mse_scores = []\n",
    "\n",
    "# Iterar sobre los folds\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Dividir los datos en entrenamiento y prueba para este fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Ajustar el modelo dentro del pipeline\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular el error cuadrado medio (MSE) para este fold\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calcular el promedio de los errores cuadrados medios de todos los folds\n",
    "average_mse = sum(mse_scores) / num_folds\n",
    "\n",
    "print(f'Error Cuadrado Medio Promedio (K-Folds): {average_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En este código, primero se carga el conjunto de datos y se separan las características (X) y la variable objetivo (y). Luego, se crea un objeto KFold con n_splits establecido en 5, lo que significa que se realizarán 5 folds.\n",
    "\n",
    "- En el bucle for, se iterará sobre cada fold, dividiendo los datos en conjuntos de entrenamiento y prueba, ajustando un modelo de regresión lineal en los datos de entrenamiento y calculando el MSE en el conjunto de prueba para cada fold. Los MSE de todos los folds se promedian para obtener el promedio de errores cuadrados medios de todos los folds.\n",
    "\n",
    "- K-Folds Cross Validation es una técnica útil para evaluar el rendimiento del modelo de manera más robusta y es especialmente útil cuando se tiene un conjunto de datos pequeño o se desea obtener una estimación más precisa del rendimiento del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scikit-learni-envjf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
