{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La \"Optimización Paramétrica con Validación Cruzada\" es un proceso en el que se busca encontrar los mejores hiperparámetros para un modelo de aprendizaje automático utilizando validación cruzada (CV) como parte del proceso de evaluación. Este enfoque es fundamental para mejorar el rendimiento de un modelo y evitar problemas de sobreajuste. A continuación, se explica este concepto en detalle y se proporciona un ejemplo:\n",
    "\n",
    "### Conceptos Clave:\n",
    "\n",
    "####Hiperparámetros: \n",
    "- Son configuraciones del modelo que no se ajustan automáticamente durante el entrenamiento, como la tasa de aprendizaje en redes neuronales o el número de árboles en un bosque aleatorio.\n",
    "\n",
    "#### Validación Cruzada (CV): \n",
    "- Es una técnica para evaluar el rendimiento de un modelo mediante la división del conjunto de datos en múltiples subconjuntos (llamados pliegues) y realizando evaluaciones iterativas. El CV ayuda a obtener una estimación más precisa del rendimiento del modelo y evitar problemas de sesgo en la evaluación.\n",
    "\n",
    "#### Optimización de Hiperparámetros: \n",
    "- Es el proceso de buscar los mejores valores para los hiperparámetros del modelo con el objetivo de mejorar su rendimiento.\n",
    "\n",
    "##### Ejemplo:\n",
    "\n",
    "- Supongamos que estamos trabajando con un conjunto de datos de clasificación y queremos encontrar los mejores hiperparámetros para un modelo de Bosque Aleatorio (Random Forest). Aquí está cómo se realiza la \"Optimización Paramétrica con Validación Cruzada\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = pd.read_csv('/home/jhonfypy/CursoML_Scikit_learni_jf/heart.csv')\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "# Definir los hiperparámetros que queremos optimizar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Crear el modelo de Bosque Aleatorio\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Realizar una búsqueda en cuadrícula con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo a los datos\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y el mejor puntaje\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Mejor puntaje de precisión encontrado:\")\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este ejemplo:\n",
    "\n",
    "- Importamos los datos y separamos las características y las etiquetas.\n",
    "- Definimos una cuadrícula de hiperparámetros que queremos optimizar.\n",
    "- Creamos un modelo de Bosque Aleatorio.\n",
    "- Utilizamos GridSearchCVpara realizar una búsqueda exhaustiva de los mejores hiperparámetros utilizando validación cruzada de 5 pliegues.\n",
    "- Ajustamos el modelo a los datos y obtenemos los mejores hiperparámetros y el mejor puntaje de precisión.\n",
    "- Este proceso nos permite encontrar la configuración de hiperparámetros que proporciona el mejor rendimiento para nuestro modelo de Bosque Aleatorio en función de la métrica de precisión, y todo esto con una evaluación más robusta gracias a la validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparametros | Hyperparameter Optimization\n",
    "\n",
    "- Familiarizados con el concepto de Cross Validation vamos a utilizar este mismo principio de fondo para lograr automatizar un poco la selección y optimización de nuestros modelos.\n",
    "\n",
    "### Problema: \n",
    "- Parece que encontramos un modelo de aprendizaje que parece funcionar, pero esto puede implicar que ahora tenemos que encontrar la optimización de cada uno de los parámetros de este modelo, encontrar el que mejor se ajuste y el que mejor resultado nos de.\n",
    "\n",
    "- Es facil perderse entre los conceptos de tantos parámetros. Tenemos flexibilidad para algoritmos básicos de Machine Learning, pero facil perderse.\n",
    "- Es difícil medir la sensibilidad de los mismos manualmente.\n",
    "- Es COSTOSO, en tiempo humano y computacionalmente.\n",
    "- Scikit Learn nos ofrece enfoques para automatizar el proceso de optimización paramétrica. Existen 3 enfoques principales, estos son:\n",
    "\n",
    "### Optimización manual\n",
    "\n",
    "- Optimizacion por grilla de parámetros | GridSearchCV\n",
    "\n",
    "- Optimizacion por búsqueda aleatorizada |\n",
    ".\n",
    ".\n",
    "- Optimización manual\n",
    "\n",
    "- Escoger el modelo que queremos ajustar.\n",
    "\n",
    "- Buscar en la documentación de Scikit-Learn\n",
    "\n",
    "- Identificar parámetros y ajustes. Parámetros que vamos a necesitar y cuáles son los posibles ajustes que vamos a requerir para cada uno de estos parámetros.\n",
    "\n",
    "- Probar combinaciones una por una iterando a través de listas.\n",
    ".\n",
    ".\n",
    "### Optimizacion por grilla de parámetros | GridSearchCV\n",
    "\n",
    "Es una forma organizada, exhaustiva y sistematica de probar todos los parametros que le digamos que tenga que probar, con los respectivos rangos de valores que le aportemos.\n",
    "\n",
    "- Definir una o varias métricas que queremos optimizar.\n",
    "- Identificar los posibles valores que pueden tener los parámetros.\n",
    "- Crear un diccionario de parámetros.\n",
    "- Usar Cross Validation.\n",
    "- Entrenar el modelo (e ir por un café)\n",
    "La grilla de parámetros nos define GRUPOS DE PARÁMETROS que serán probados en todas sus combinaciones (Un grupo a la vez)\n",
    "\n",
    "### Ejemplo:\n",
    "![Alt text](image.png)\n",
    "#### svm-gridsearch-optimized\n",
    ".\n",
    ".\n",
    "\n",
    "## Optimizacion por búsqueda aleatorizada | RandomizedSearchCV\n",
    "\n",
    "- Si no tenemos tanto tiempo para una prueba tan exhaustiva o queremos combinaciones aleatorias usaremos este metodo. Es lo mismo que el caso anterior, pero busca de forma aleatoria los parametros y Scikit Learn selecciona los mejores de las combinaciones aleatorias que se hicieron.\n",
    "\n",
    "- En este método, definimos escalas de valores para cada uno de los parámetros seleccionados, el sistema probará varias iteraciones (Configurables según los recursos) y mostrará la mejor combinación encontrada.\n",
    "\n",
    "### Ejemplo:\n",
    "![Alt text](image-1.png)\n",
    "#### svm-randomized-search-optimized\n",
    ".\n",
    ".\n",
    "\n",
    "## GridSearchCV vs RandomizedSearchCV\n",
    "\n",
    "#### GridSearchCV\n",
    "\n",
    "- Cuando se quiera realizar un estudio a fondo sobre las implicaciones de los parámetros.\n",
    "Se tenga tiempo.\n",
    "Se tenga poder de procesamiento.\n",
    "RandomizedSearchCV\n",
    "![Alt text](image-2.png)\n",
    "- Cuando se quiera explorar posibles optimizaciones.\n",
    "Haya poco tiempo.\n",
    "Haya poco poder de procesamiento.\n",
    "GridSearch-vs-RandomizedSearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scikit-learni-envjf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
